{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1b64dfad-6b53-4b69-b35f-5e062b712cd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "import pandas_tfrecords as pdtfr\n",
    "\n",
    "\n",
    "dataset_path = '../../datasets/next_day_wildfire_csv/'\n",
    "\n",
    "save_path = \"../../datasets/next_day_wildfire_compiled/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2df8769b-f7f0-4533-932c-768e29d9b403",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next_day_wildfire_spread_train_14.csv\n",
      "next_day_wildfire_spread_train_03.csv\n",
      "next_day_wildfire_spread_train_10.csv\n",
      "next_day_wildfire_spread_train_02.csv\n",
      "next_day_wildfire_spread_train_04.csv\n",
      "next_day_wildfire_spread_train_13.csv\n",
      "next_day_wildfire_spread_test_00.csv\n",
      "next_day_wildfire_spread_train_12.csv\n",
      "next_day_wildfire_spread_train_01.csv\n",
      "next_day_wildfire_spread_train_07.csv\n",
      "next_day_wildfire_spread_eval_01.csv\n",
      "next_day_wildfire_spread_train_05.csv\n",
      "next_day_wildfire_spread_train_00.csv\n",
      "next_day_wildfire_spread_train_06.csv\n",
      "next_day_wildfire_spread_train_08.csv\n",
      "next_day_wildfire_spread_eval_00.csv\n",
      "next_day_wildfire_spread_train_09.csv\n",
      "next_day_wildfire_spread_test_01.csv\n",
      "next_day_wildfire_spread_train_11.csv\n"
     ]
    }
   ],
   "source": [
    "# checking filenames and setting dataset path\n",
    "\n",
    "for subdirs, dirs, files in os.walk(dataset_path):\n",
    "    for file in files:\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0a92901f-ddf6-4f26-aaaf-e7b7b5e5db2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING SETS 15\n",
      "TEST SETS 2\n",
      "EVAL SETS 2\n",
      "TRAIN\n",
      "(979, 13)\n",
      "(1000, 13)\n",
      "(1000, 13)\n",
      "(1000, 13)\n",
      "(1000, 13)\n",
      "(1000, 13)\n",
      "(1000, 13)\n",
      "(1000, 13)\n",
      "(1000, 13)\n",
      "(1000, 13)\n",
      "(1000, 13)\n",
      "(1000, 13)\n",
      "(1000, 13)\n",
      "(1000, 13)\n",
      "(1000, 13)\n",
      "TEST\n",
      "(1000, 13)\n",
      "(689, 13)\n",
      "EVAL\n",
      "(877, 13)\n",
      "(1000, 13)\n"
     ]
    }
   ],
   "source": [
    "dftrain_list = []\n",
    "dftest_list = []\n",
    "dfeval_list = []\n",
    "\n",
    "for subdirs, dirs, files in os.walk(dataset_path):\n",
    "    for file in files:\n",
    "        if file.find(\"train\") > 0:\n",
    "            # print(file)\n",
    "            dftrain_list.append(pd.read_csv(dataset_path + file))\n",
    "        if file.find(\"eval\") > 0:\n",
    "            # print(file)\n",
    "            dfeval_list.append(pd.read_csv(dataset_path + file))\n",
    "        if file.find(\"test\") > 0:\n",
    "            # print(file)\n",
    "            dftest_list.append(pd.read_csv(dataset_path + file))\n",
    "    print(\"TRAINING SETS\", len(dftrain_list))\n",
    "    print(\"TEST SETS\", len(dftest_list))\n",
    "    print(\"EVAL SETS\", len(dfeval_list))\n",
    "\n",
    "print(\"TRAIN\")\n",
    "for df in dftrain_list:\n",
    "    df = df.reindex(sorted(df.columns), axis=1)\n",
    "    print(df.shape)\n",
    "\n",
    "print(\"TEST\")\n",
    "for df in dftest_list:\n",
    "    df = df.reindex(sorted(df.columns), axis=1)\n",
    "    print(df.shape)\n",
    "\n",
    "print(\"EVAL\")\n",
    "for df in dfeval_list:\n",
    "    df = df.reindex(sorted(df.columns), axis=1)\n",
    "    print(df.shape)\n",
    "\n",
    "\n",
    "    # headings = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e4ba318e-ca71-4f15-94a8-c48854519f80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14979, 13)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1689, 13)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1877, 13)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dftrain = dftrain_list[0]\n",
    "for i in range(1, len(dftrain_list)):\n",
    "    dftrain = pd.concat([dftrain, dftrain_list[i]], axis=0)\n",
    "\n",
    "display(dftrain.shape)\n",
    "\n",
    "dftest = dftest_list[0]\n",
    "for i in range(1, len(dftest_list)):\n",
    "    dftest = pd.concat([dftest, dftest_list[i]], axis=0)\n",
    "\n",
    "display(dftest.shape)\n",
    "    \n",
    "dfeval = dfeval_list[0]\n",
    "for i in range(1, len(dfeval_list)):\n",
    "    dfeval = pd.concat([dfeval, dfeval_list[i]], axis=0)\n",
    "    \n",
    "display(dfeval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "11e770eb-fe4f-4558-99d9-82ed9c010e0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.mkdir(save_path)\n",
    "\n",
    "# print(\"HEADINGS\", headings)\n",
    "\n",
    "dftrain.to_csv(save_path + \"next_day_wildfire_train.csv\")\n",
    "dftest.to_csv(save_path + \"next_day_wildfire_test.csv\")\n",
    "dfeval.to_csv(save_path + \"next_day_wildfire_eval.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6d1f24-5432-4852-92ac-02da10d141df",
   "metadata": {},
   "outputs": [],
   "source": [
    "### WARNING ###\n",
    "# THIS CELL IS USED TO DELETE THE CSV FOLDER #\n",
    "\n",
    "for subdirs, dirs, files in os.walk(save_path):\n",
    "    # This function will gene\n",
    "    for file in files:\n",
    "        os.remove(save_path + file)\n",
    "\n",
    "os.rmdir(save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
